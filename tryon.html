<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tajaah Virtual Try-On</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #f4f4f4;
      font-family: sans-serif;
      text-align: center;
    }
    canvas, video {
      position: absolute;
      left: 50%;
      top: 50%;
      transform: translate(-50%, -50%);
    }
    #overlayImg {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <p>try on</p>
  
  <video id="video" autoplay playsinline muted width="640" height="480"></video>
  <canvas id="canvas" width="640" height="480"></canvas>
  <img id="overlayImg" src="toptest.png" style="display:none;" />

  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar.js"></script>

  <a-scene embedded arjs>
     <a-marker preset="hiro">
        <a-box position="0 0.5 0" material="color: red;"></a-box>
       </a-marker>
   <a-entity camera></a-entity>
  </a-scene>
  <script type="module">

    
    import { Pose } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs';

    // Create Pose instance
   const pose = new Pose({
  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/${file}`,
});
    
// Set up the callback to process the results
    pose.onResults((results) => {
      console.log(results.poseLandmarks);  // Log pose landmarks to the console
    });

    async function init() {
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      const overlayImg = document.getElementById('overlayImg');

      // Start webcam
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      // Load Pose model
      const pose = await Pose.createFromOptions(Pose.SupportedModels.BlazePose, {
        runtime: 'mediapipe',
        modelType: 'full'
      });

      // Access the webcam
    const videoElement = document.getElementById('video');

    navigator.mediaDevices.getUserMedia({ video: true })
      .then((stream) => {
        videoElement.srcObject = stream;
        videoElement.play();

        // Continuously process frames from the webcam
        videoElement.onplay = () => {
          const processFrame = async () => {
            await pose.send({ image: videoElement });
            requestAnimationFrame(processFrame);
          };
          processFrame();
        };
      })
      .catch((err) => {
        console.error('Error accessing webcam: ', err);
      });

      video.addEventListener('loadeddata', () => {
        requestAnimationFrame(update);
      });

      async function update() {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        const result = await pose.estimatePoses(video);
        if (result.length > 0) {
          const keypoints = result[0].keypoints;

          const leftShoulder = keypoints.find(p => p.name === 'left_shoulder');
          const rightShoulder = keypoints.find(p => p.name === 'right_shoulder');

          if (leftShoulder && rightShoulder) {
            const shoulderX = (leftShoulder.x + rightShoulder.x) / 2;
            const shoulderY = (leftShoulder.y + rightShoulder.y) / 2;
            const shoulderWidth = Math.abs(rightShoulder.x - leftShoulder.x);

            const imgWidth = shoulderWidth * 2.5;
            const imgHeight = imgWidth * (overlayImg.naturalHeight / overlayImg.naturalWidth);
            const x = shoulderX - imgWidth / 2;
            const y = shoulderY - imgHeight / 4;

            ctx.drawImage(overlayImg, x, y, imgWidth, imgHeight);
          }
        }

        requestAnimationFrame(update);
      }
    }

    init();
  </script>
</body>
</html>
